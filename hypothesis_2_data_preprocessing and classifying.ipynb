{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import clean, seq_gen, get_Xy, make_homogenous_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION=r'C:\\Users\\Asus\\Videos\\paper lstm transform\\rethesis2014arnab\\NonSMOTE\\NonSMOTE\\yeast5\\yeast5-5-fold'\n",
    "TRAIN_DATA='yeast5-5-5tra.dat'\n",
    "TEST_DATA='yeast5-5-5tst.dat'\n",
    "TRAIN_DATA_=os.path.join(FILE_LOCATION,TRAIN_DATA)\n",
    "TEST_DATA_=os.path.join(FILE_LOCATION, TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=clean(TRAIN_DATA_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3    4    5     6     7  8\n",
       "0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22  0\n",
       "1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22  0\n",
       "2  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22  0\n",
       "3  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22  0\n",
       "4  0.51  0.40  0.56  0.17  0.5  0.5  0.49  0.22  0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_generation(data, pos=0, mj=0, mn=1):\n",
    "    '''\n",
    "    input: data of DataFrame, mj: majority class label, mn: minority class label\n",
    "    \n",
    "    output: numpy tensor of shape (timsteps, 2*min_sample_size, features)\n",
    "            at each timestep, majority class and minority class samples distribution is equal\n",
    "    '''\n",
    "    data_mj=data[data[str(len(data.columns)-1)]==mj]\n",
    "    data_mj=np.array(data_mj)\n",
    "    data_mn=data[data[str(len(data.columns)-1)]==mn]\n",
    "    data_mn=np.array(data_mn)\n",
    "    \n",
    "    majority_data_iterator=0\n",
    "    \n",
    "    '''seq_len is the number of timesteps.'''\n",
    "\n",
    "    seq_len=(data_mj.shape[0]//data_mn.shape[0])+1\n",
    "\n",
    "    '''batch_size = number of minority samples'''\n",
    "    #print('data_mj shape:', data_mj.shape)\n",
    "    #print('data_mn shape:', data_mn.shape)\n",
    "    \n",
    "    batch_size=data_mn.shape[0]\n",
    "    #print('batch_size:', batch_size)\n",
    "    seq=np.zeros((seq_len, data_mn.shape[0], data_mn.shape[1]))\n",
    "    #print('sequence shape:', seq.shape)\n",
    "    #print('data_mj[]:', data_mj[2*batch_size:2*batch_size+batch_size].shape)\n",
    "    \n",
    "    for i in range(seq_len):\n",
    "        if i!=pos:\n",
    "            seq[i]=data_mj[(majority_data_iterator*batch_size):( (majority_data_iterator*batch_size)+batch_size)]\n",
    "            majority_data_iterator+majority_data_iterator+1\n",
    "            \n",
    "        else:\n",
    "            seq[i]=data_mn\n",
    "            #print('data')\n",
    "            #print(seq[i].shape)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=seq_generation(train_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx,trainy=get_Xy(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=torch.from_numpy(trainx).float()\n",
    "trainy=torch.from_numpy(trainy).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=clean(TEST_DATA_).values\n",
    "testx=torch.from_numpy(test_data[:,:-1]).float()\n",
    "testy=torch.from_numpy(test_data[:,-1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm=nn.LSTMCell(8,32)\n",
    "        self.l=nn.Linear(32,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output,_=self.lstm(x)\n",
    "        output=self.l(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimizer=torch.optim.SGD(m.parameters(),lr=0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def train_epoch(model,optim,criterion,trainx,trainy):\n",
    "    model.train()\n",
    "    loss=0\n",
    "    losses=[]\n",
    "    optim.zero_grad()\n",
    "    l=0\n",
    "    for i in range(trainx.shape[0]):\n",
    "        n=model(trainx[i])\n",
    "        l=l+criterion(n,trainy[i].view(trainy[i].shape[0],1))\n",
    "        #l.backward(retain_graph=True) #this works too\n",
    "        \n",
    "        #if i==(trainx.shape[0]-1):\n",
    "         #   losses.append(l.data.numpy())\n",
    "    losses.append(l.data.numpy())\n",
    "    loss=l\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_losses = []\n",
    "num_epochs = 20\n",
    "for i in range(2000):\n",
    "    \n",
    "    train_seq=seq_generation(train_data,i%32)\n",
    "    trainx, trainy=get_Xy(train_seq)\n",
    "    trainx=torch.from_numpy(trainx).float()\n",
    "    trainy=torch.from_numpy(trainy).float()\n",
    "    e_losses+=train_epoch(m,optimizer,criterion,trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x93276b9a08>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFzZJREFUeJzt3X2UXHV9x/HPd2Z2N2Q3D7vJBkIe2BAoFBRCWJ5ErRVFRMtDqVSO1RzFBs+RFk61NUVraXvao0Wwx1qxKBygIqAHUCoIRA6UUiGwwZAEYgh5AEJCsuzmOZt9mm//mLtxsuzMnZ2dh/1N3q9z5szd396Z+82dyWfu/u7v/sbcXQCA8CWqXQAAoDQIdACoEQQ6ANQIAh0AagSBDgA1gkAHgBpBoANAjSDQAaBGEOgAUCNSldzY9OnTva2trZKbBIDgLV++/G13b41br6KB3tbWpo6OjkpuEgCCZ2avFbIeXS4AUCMIdACoEQQ6ANSI2EA3szlm9oSZrTGzl8zsmqj9ejN708xWRLcLy18uACCXQk6KDkj6kru/YGaTJC03s6XR777t7t8qX3kAgELFBrq7b5W0NVreY2ZrJM0qd2EAgNEZVR+6mbVJOk3SsqjpajNbaWa3mVlziWsDAIxCwYFuZk2S7pN0rbvvlnSzpPmSFihzBH9jjsctNrMOM+vo7OwsqsjH12zT9558tajHAsDhoqBAN7M6ZcL8Lne/X5LcfZu7D7p7WtIPJJ050mPd/RZ3b3f39tbW2AudRvTk2k798H83FvVYADhcFDLKxSTdKmmNu9+U1T4za7VLJa0ufXkAgEIVMsrlXEmflrTKzFZEbddJusLMFkhySZskXVWWCgEABSlklMvTkmyEXz1c+nLy1lHJzQFAcIK4UtRG+jgBABwiiEAHAMQLJtDpcAGA/IIIdHpcACBeEIEOAIhHoANAjQgm0Bm1CAD5BRHoxrhFAIgVRKADAOIFE+hcKQoA+QUT6ACA/Ah0AKgRBDoA1IhgAp0edADIL4hAZ9QiAMQLItABAPHCCXT6XAAgryAC3ZhvEQBiBRHoAIB4BDoA1IhgAp0udADIL4hAZ9giAMQLItABAPEIdACoEcEEOtPnAkB+QQQ6XegAEC+IQAcAxAsm0OlwAYD8ggh0hi0CQLwgAh0AEI9AB4AaEUygM2oRAPKLDXQzm2NmT5jZGjN7ycyuidpbzGypma2L7pvLVaTRiQ4AsQo5Qh+Q9CV3/31JZ0v6opmdJGmJpMfd/XhJj0c/AwCqJDbQ3X2ru78QLe+RtEbSLEkXS7ojWu0OSZeUq0hJcgYuAkBeo+pDN7M2SadJWibpSHffKmVCX9KMUhd3cLvlemIAqCEFB7qZNUm6T9K17r57FI9bbGYdZtbR2dlZTI0AgAIUFOhmVqdMmN/l7vdHzdvMbGb0+5mSto/0WHe/xd3b3b29tbW1FDUDAEZQyCgXk3SrpDXuflPWrx6UtChaXiTp56Uv73cYtggA+aUKWOdcSZ+WtMrMVkRt10n6hqSfmNmVkl6X9InylCg60QGgALGB7u5PK3eknlfacgAAxQrnStFqFwAA41wQgW70uQBArCACHQAQj0AHgBoRTqDTiQ4AeQUR6Ey2CADxggh0AEC8YAKd2RYBIL8gAp0eFwCIF0SgAwDiEegAUCOCCXRmWwSA/IIIdIYtAkC8IAIdABCPQAeAGhFMoNOFDgD5BRHoTJ8LAPGCCHQAQLxgAt0ZtwgAeQUR6AxbBIB4QQQ6ACAegQ4ANSKYQKcHHQDyCyLQ6UIHgHhBBDoAIF4wgc6oRQDIL4xAZ9wiAMQKI9ABALEIdACoEQQ6ANSIIAKdHnQAiBdEoAMA4sUGupndZmbbzWx1Vtv1Zvamma2IbheWt8wMZlwEgNwKOUK/XdIFI7R/290XRLeHS1vWoRi1CADxYgPd3Z+S1F2BWgAAYzCWPvSrzWxl1CXTXLKKAABFKTbQb5Y0X9ICSVsl3ZhrRTNbbGYdZtbR2dlZ5OYy6EIHgNyKCnR33+bug+6elvQDSWfmWfcWd2939/bW1taiiuRLogEgXlGBbmYzs368VNLqXOsCACojFbeCmd0t6QOSppvZZkl/L+kDZrZAme+d2CTpqjLWCAAoQGygu/sVIzTfWoZaYtGFDgC5BXGlKOPQASBeEIEOAIgXVKBz6T8A5BZEoNPjAgDxggh0AEA8Ah0AakRQgU4POgDkFkSgM2wRAOIFEegAgHhBBTqjFgEgtyAC3ehzAYBYQQQ6ACAegQ4ANSKoQHcGLgJATkEFOgAgNwIdAGpEUIHOsEUAyC2IQGfUIgDECyLQAQDxCHQAqBEEOgDUiCAC3fjOIgCIFUSgAwDiEegAUCOCCnTGoQNAbkEEOuPQASBeEIEOAIgXVKAz2yIA5BZEoNPjAgDxggh0AEA8Ah0AakRQgc6wRQDILTbQzew2M9tuZquz2lrMbKmZrYvum8tZJMMWASBeIUfot0u6YFjbEkmPu/vxkh6PfgYAVFFsoLv7U5K6hzVfLOmOaPkOSZeUuK6Ra6nERgAgUMX2oR/p7lslKbqfUbqS3onZFgEgXtlPiprZYjPrMLOOzs7Ocm8OAA5bxQb6NjObKUnR/fZcK7r7Le7e7u7tra2tRW4OABCn2EB/UNKiaHmRpJ+Xppz8nHGLAJBTIcMW75b0jKQTzGyzmV0p6RuSPmxm6yR9OPq5bBi2CADxUnEruPsVOX51XolrAQCMQVhXila7AAAYx4IKdABAbgQ6ANQIAh0AakRQgc6oRQDILYhAN8YtAkCsIAIdABAvrECnywUAcgoi0OlwAYB4QQQ6ACAegQ4ANSKoQHc60QEgpyACPZXM9KIPpgl0AMgliEBPGIEOAHGCCPRUIhPoAwQ6AOQURKAnExyhA0AcAh0AakRQgU6XCwDkFkSgpxKZMtNMtwgAOQUR6MmoyoFBAh0Acgkk0DNl0ocOALkFEehDwxYH6XIBgJyCCPTEwVEu6SpXAgDjVxCBfvDCIvrQASCnIAI9SZcLAMQKK9A5KQoAOQUV6FxYBAC5BRHoQ33oaQIdAHIKItCHps/lCB0Acgsi0PmCCwCIF0agc1IUAGIFEeh8YxEAxEuN5cFmtknSHkmDkgbcvb0URQ03NNti/yBXigJALmMK9MgfuvvbJXienBobkpKk/X2D5dwMAAQtiC6XKUfUSZJ27u+vciUAMH6NNdBd0mNmttzMFpeioJGkkgk1NaS0s6evXJsAgOCNtcvlXHffYmYzJC01s9+6+1PZK0RBv1iS5s6dW/SGphxRp10coQNATmM6Qnf3LdH9dkkPSDpzhHVucfd2d29vbW0teltHTZmgzTt6in48ANS6ogPdzBrNbNLQsqTzJa0uVWHDnXz0ZL20ZZd6ODEKACMaS5fLkZIesMwY8ZSkH7v7IyWpagQfP+Vo3fnMa7r0e/+nU2ZP0YxJE9TcWK9pjfVqGXabUJcsVxkAMG4VHejuvkHSqSWsJa8z57Xo3/50ge58ZpOeWNuprr29ynWdUWN9UkdNmaB505s0v7VR82c0aeHcZs1vbVT0AQQANacU49Ar5pLTZumS02ZJysy8uKunX137+rRjf5+69vape1+fuvf1qmtfn7bs7NGGzn166pVO9UUXJDVPrNM586fpwnfP1AdPnKGJ9UH98wEgr2ATLZEwNTfWq7mxPu96g2nXxrf3avlrO/T8ph16cm2nHl71lpoaUvrU2XP1+fceq9ZJDRWqGgDKx7yCX+vW3t7uHR0dFdveSAbTrmUbu/TjZa/r4VVb1diQ0lcuOFGfOmsu3TEAxiUzW17I1CrBHqEXK5kwvWf+dL1n/nSt79yrv/vZan3tZ6v16/Vv61ufOJVuGADBCuLS/3KZ39qkuz5/lq678EQ9svotfebW57Svd6DaZQFAUQ7rQJckM9Pi98/Xv1+xUC+8vkN/fmcHszoCCNJhH+hDPnbKTN3wJ6fq1+u79M8PrSnqOb7z+Dpd9N2ntb+Po3wAlUegZ7ns9Nm68r3zdPuvN+mhlVtH9djegUHdtPQVrdy8Syd9/dEyVQgAuRHowyz56Ik6dfYUfe1nq7R9z4GCH8e3KQGoNgJ9mLpkQjdevkD7+wZ13f2rVeiwTgIdQLUR6CM4bkaT/vojJ+hXa7bpp8s3F/SYgUECHUB1Eeg5fO7ceTprXov+8b9f1hvd+2PXHxh2hH5fgR8EAFAqBHoOiYTpxsszc4996ScvxnapDP/9sxu6ylYbAIyEQM9jdvNEXX/RyXpuU7f+86n1edcdPnY9wTQCACqMQI9x2cJZ+ti7Z+pbj67Vr17elnO94Ufo93a8Ue7SAOAQBHoMM9MNnzhF75o1RX9x92/03MbuEdcb3ocuScdd97B29fA9qAAqg0AvwMT6lH64qF0zp07Qp29dpkdWv/Oio76Bd04XMJB2nfoPj6ltyUNqW/KQlr/WXfAwSAAYLaYWLNCMSRP006vO0efu6NAXfvSC/uzsufqbC07U5Al1kqQ9B+KPxC+7+ZlDfv7kGXP0l+cdr6OnHlGWmgEcXgj0UZjW1KCfXHW2bnhkrX749Eb9ctVbuuZDx+vy9jnac2D087fc8/wbuuf5d/a1X/UHx+qz75mno6ZMKEXZAA4Th90XXJTKqs279E+/eFnPbepW88Q6NTfWa0PnPj149blqakipbVqjnnxluxbfuXzE/vViTG9q0KJzjtGFp8zUsdP5flTgcFHoF1wQ6GPg7lq2sVu3Pb1RS9ds05zmiXriyx9QMjFy0KbTruc2detfHl6jlZt3la2uM9qa9cETj9RZx7bo5KMnqyGVLNu2AJQfgV5h3fv6lErawT710RhMu57d0KUbHl2rFW/sLEN1+S2YM1XnzJ+mM9qa9a5ZU9Ta1MDRPzCOEOg1wN31RneP7u14XTc/uV7jaf6vSRNSOmveNC08ZqoWzJ6qE46apJbGej4IgDIg0A8Tuw/065n1XVr68jb9YuUWHegf/9+2dNyMJp0+t1kL5k7VyUdP1nEzmvguVyAPAh2HcHdt39Or5a/t0LMbuvTUK53a1BU/6dh40lif1HuOm64z21p02typOnHmZDU18EGA2kegY8zSadfW3Qe0ZsturXhjp5a/tkPPbeoObu73M+e16Iy2Zp0ye6pOmjlZR089IueJa2A8ItBRVe6uXT39Wt+5V2vf2qu1b+3Wyjd36cU3do6rcwGFOn5Gk+a3NumYaRM1d9pEzZwyQTMmTVDrpAY1T6xXfYqLrlE+hQY6f6+iLMxMUyfW6/RjWnT6MS1FP0/fQFpbdvZow9t7tX77Pq3dtkcvb9mtl7fuLmG18dZt36t12/dWdJuSNK2xXq2TGjS9qUEtjfVqaazXlCPqNHVinZoaUpp8ROZ+Yn1SE+tTmlCX0IS6pOqSCdWnEkolTMmEKWkmM3HSusYR6BjX6lMJtU1vVNv0Rn3wxLE918BgWtv39Oqt3Qe0ZWePXuvar807evR69z5tenu/3tzZU5qiS6hrX5+69vVJ2lPtUoqSSpjqUwnVJTO3+uShP9elMm2pRGa5LmFKJe3g75OJzHIqam9IJTW3ZaJSSTv4YZWw6EMr+uAaWk4lTHbwZx1cL5XIfNjVJxMHtzW0PLS9RIk//AbTXvLnHAmBjsNGKpnQ0VOP0NFTj9DCuc0V2+5g2rW/b0D7ege1t3dA+3oHtOfAgHYf6Nfe6H7n/n7t6unXzp5+9fYPqmlCSnsPDKh7X5+69/Xp7b292l3E9BLVNpB2DfQNShqsdiklU59MyOx3HxBmOvjBkjk1k7kf+jmRMO05MKAfXXmW3j17SllrI9CBMksmTJMm1GlSERedhWTofJy75Mp8kKXdNZj2TLAPptU/6OofTKt3YFC9A2n1DqR1oH9QB/oH1duf1oGBQfX0pdUTtaWzTrh49NxHTWlQMpGQu8tdSrsr7ZLLlU77wfWGtq+DtWTWGfqdDz3GFT0uWo6e1901mNbB50i7K5kw1ScTB7eZeR7X4FAN7kqn9Y7nGvprotwIdAAlMdSdMNSrwEiiyhvTqXkzu8DM1prZq2a2pFRFAQBGr+hAN7OkpP+Q9FFJJ0m6wsxOKlVhAIDRGcsR+pmSXnX3De7eJ+keSReXpiwAwGiNJdBnScr+dobNURsAoArGEugjnfF4xzWAZrbYzDrMrKOzs3MMmwMA5DOWQN8saU7Wz7MlbRm+krvf4u7t7t7e2to6hs0BAPIZS6A/L+l4M5tnZvWSPinpwdKUBQAYraLHobv7gJldLelRSUlJt7n7SyWrDAAwKhWdbdHMOiW9VuTDp0t6u4TllAp1jQ51jc54rUsav7XVYl3HuHtsn3VFA30szKyjkOkjK426Roe6Rme81iWN39oO57qYxBkAagSBDgA1IqRAv6XaBeRAXaNDXaMzXuuSxm9th21dwfShAwDyC+kIHQCQRxCBXq1pes1sjpk9YWZrzOwlM7smar/ezN40sxXR7cKsx/xtVOdaM/tImevbZGaroho6orYWM1tqZuui++ao3czsO1FtK81sYZlqOiFrv6wws91mdm019pmZ3WZm281sdVbbqPePmS2K1l9nZovKVNcNZvbbaNsPmNnUqL3NzHqy9tv3sx5zevT6vxrVPqYJyHPUNerXrdT/X3PUdW9WTZvMbEXUXsn9lSsfqvcey3zrx/i9KXPR0npJx0qql/SipJMqtO2ZkhZGy5MkvaLMVMHXS/ryCOufFNXXIGleVHeyjPVtkjR9WNu/SloSLS+R9M1o+UJJv1RmDp6zJS2r0Gv3lqRjqrHPJL1f0kJJq4vdP5JaJG2I7puj5eYy1HW+pFS0/M2sutqy1xv2PM9JOieq+ZeSPlqGukb1upXj/+tIdQ37/Y2Svl6F/ZUrH6r2HgvhCL1q0/S6+1Z3fyFa3iNpjfLPKHmxpHvcvdfdN0p6VZn6K+liSXdEy3dIuiSr/U7PeFbSVDObWeZazpO03t3zXUxWtn3m7k9J6h5he6PZPx+RtNTdu919h6Slki4odV3u/pi7D31p6LPKzI2UU1TbZHd/xjOpcGfWv6VkdeWR63Ur+f/XfHVFR9mXS7o733OUaX/lyoeqvcdCCPRxMU2vmbVJOk3Ssqjp6ujPptuG/qRS5Wt1SY+Z2XIzWxy1HenuW6XMG07SjCrVJmXm98n+jzYe9tlo90819tvnlDmSGzLPzH5jZv9jZu+L2mZFtVSirtG8bpXeX++TtM3d12W1VXx/DcuHqr3HQgj0gqbpLWsBZk2S7pN0rbvvlnSzpPmSFkjaqsyffFLlaz3X3Rcq861RXzSz9+dZt6K1WWbCtosk/TRqGi/7LJdcdVR6v31V0oCku6KmrZLmuvtpkv5K0o/NbHIF6xrt61bp1/MKHXrQUPH9NUI+5Fw1Rw0lqy2EQC9omt5yMbM6ZV6su9z9fkly923uPujuaUk/0O+6CCpaq7tvie63S3ogqmPbUFdKdL+9GrUp8yHzgrtvi2ocF/tMo98/FasvOhn2cUmfiroFFHVpdEXLy5Xpn/69qK7sbpmy1FXE61bJ/ZWS9MeS7s2qt6L7a6R8UBXfYyEEetWm6Y36526VtMbdb8pqz+57vlTS0Nn3ByV90swazGyepOOVORFTjtoazWzS0LIyJ9VWRzUMnSVfJOnnWbV9JjrTfrakXUN/FpbJIUdO42GfZW1vNPvnUUnnm1lz1N1wftRWUmZ2gaSvSLrI3fdntbda5vt7ZWbHKrN/NkS17TGzs6P36Wey/i2lrGu0r1sl/79+SNJv3f1gV0ol91eufFA132NjOctbqZsyZ4dfUebT9qsV3O57lfnTZ6WkFdHtQkn/JWlV1P6gpJlZj/lqVOdajfEsekxtxyozguBFSS8N7RdJ0yQ9LmlddN8StZsyX+q9Pqq9vYy1TZTUJWlKVlvF95kyHyhbJfUrcxR0ZTH7R5k+7Vej22fLVNeryvSjDr3Pvh+te1n0+r4o6QVJf5T1PO3KBOx6Sd9VdKFgiesa9etW6v+vI9UVtd8u6QvD1q3k/sqVD1V7j3GlKADUiBC6XAAABSDQAaBGEOgAUCMIdACoEQQ6ANQIAh0AagSBDgA1gkAHgBrx/8YCGqUJgTmLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logit_predictions=m(testx)\n",
    "    prediction_probabilities=torch.sigmoid(logit_predictions)\n",
    "    \n",
    "    preds=torch.round(prediction_probabilities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(preds,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5%14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
